"""
ML Automation Pipeline - Skinlytics Platform

Sistema completamente automatizado de Machine Learning que executa:
- Retreino di√°rio de modelos
- Detec√ß√£o autom√°tica de oportunidades
- Envio de alertas inteligentes
- Monitoramento de performance
- Auto-scaling baseado em dados

Features:
    - Retreino autom√°tico com novos dados
    - Ensemble learning com m√∫ltiplos modelos
    - Sistema de alertas baseado em IA
    - Performance tracking e drift detection
    - Auto-deployment de modelos melhorados

Author: CS2 Skin Tracker Team - Skinlytics Platform
Version: 2.0.0 Full Automation
"""

import asyncio
import logging
import schedule
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import json
import pickle
import numpy as np
import pandas as pd
from dataclasses import dataclass, asdict
import threading
from concurrent.futures import ThreadPoolExecutor
import os

# ML and analytics
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score
import joblib

# Internal imports
from src.ml.prediction_engine import prediction_engine, PredictionResult, OpportunityAlert
from src.services.notification_service import notification_service
from src.models.hybrid_database import create_hybrid_database

logger = logging.getLogger(__name__)

@dataclass
class ModelPerformanceMetrics:
    """M√©tricas de performance de modelo"""
    model_name: str
    item_name: str
    accuracy_24h: float
    accuracy_7d: float
    mae: float
    mse: float
    r2: float
    precision: float
    recall: float
    f1_score: float
    training_samples: int
    test_samples: int
    feature_importance: Dict[str, float]
    last_updated: datetime
    drift_score: float
    confidence_avg: float

@dataclass
class AutomationConfig:
    """Configura√ß√£o da automa√ß√£o"""
    retrain_interval_hours: int = 24
    opportunity_check_interval_minutes: int = 30
    model_types: List[str] = None
    min_training_samples: int = 1000
    max_models_per_item: int = 3
    performance_threshold: float = 0.7
    drift_threshold: float = 0.3
    confidence_threshold: float = 0.75
    top_items_to_monitor: int = 100
    
    def __post_init__(self):
        if self.model_types is None:
            self.model_types = ["xgboost", "prophet", "ensemble"]

class MLAutomationEngine:
    """Engine de automa√ß√£o completa de ML"""
    
    def __init__(self, config: AutomationConfig = None):
        self.config = config or AutomationConfig()
        self.hybrid_db = None
        self.performance_history = {}
        self.model_registry = {}
        self.running = False
        self.scheduler_thread = None
        
        # M√©tricas de sistema
        self.system_metrics = {
            "models_trained_today": 0,
            "opportunities_detected_today": 0,
            "alerts_sent_today": 0,
            "total_predictions_made": 0,
            "avg_model_accuracy": 0.0,
            "system_uptime_start": datetime.utcnow()
        }
        
        # Criar diret√≥rios
        Path("ml_automation/models").mkdir(parents=True, exist_ok=True)
        Path("ml_automation/logs").mkdir(parents=True, exist_ok=True)
        Path("ml_automation/reports").mkdir(parents=True, exist_ok=True)
        
        # Configurar logging especializado
        self._setup_logging()
        
        logger.info("ü§ñ MLAutomationEngine inicializado")
    
    def _setup_logging(self):
        """Configura logging especializado para automa√ß√£o"""
        automation_logger = logging.getLogger("ml_automation")
        automation_logger.setLevel(logging.INFO)
        
        # Handler para arquivo de automa√ß√£o
        handler = logging.FileHandler("ml_automation/logs/automation.log")
        formatter = logging.Formatter(
            '%(asctime)s [%(name)s] [%(levelname)s] %(message)s'
        )
        handler.setFormatter(formatter)
        automation_logger.addHandler(handler)
    
    async def start_automation(self):
        """Inicia o sistema de automa√ß√£o completa"""
        logger.info("üöÄ Iniciando automa√ß√£o completa de ML...")
        
        self.running = True
        
        # Conectar ao banco
        self.hybrid_db = create_hybrid_database()
        await self.hybrid_db.connect()
        
        # Configurar agendamentos
        self._setup_schedules()
        
        # Iniciar thread do scheduler
        self.scheduler_thread = threading.Thread(target=self._run_scheduler, daemon=True)
        self.scheduler_thread.start()
        
        # Executar primeira an√°lise
        await self._initial_setup()
        
        logger.info("‚úÖ Automa√ß√£o de ML iniciada com sucesso!")
    
    def _setup_schedules(self):
        """Configura todos os agendamentos"""
        # Retreino de modelos (di√°rio √†s 3h)
        schedule.every().day.at("03:00").do(
            lambda: asyncio.create_task(self._daily_model_retraining())
        )
        
        # Detec√ß√£o de oportunidades (a cada 30 minutos)
        schedule.every(self.config.opportunity_check_interval_minutes).minutes.do(
            lambda: asyncio.create_task(self._opportunity_detection_cycle())
        )
        
        # Monitoramento de performance (a cada 6 horas)
        schedule.every(6).hours.do(
            lambda: asyncio.create_task(self._performance_monitoring())
        )
        
        # Relat√≥rio di√°rio (√†s 8h)
        schedule.every().day.at("08:00").do(
            lambda: asyncio.create_task(self._generate_daily_report())
        )
        
        # Limpeza e manuten√ß√£o (√†s 2h)
        schedule.every().day.at("02:00").do(
            lambda: asyncio.create_task(self._system_maintenance())
        )
        
        # Backup de modelos (semanalmente)
        schedule.every().sunday.at("01:00").do(
            lambda: asyncio.create_task(self._backup_models())
        )
    
    def _run_scheduler(self):
        """Executa o scheduler em thread separada"""
        while self.running:
            schedule.run_pending()
            time.sleep(60)  # Check every minute
    
    async def _initial_setup(self):
        """Setup inicial do sistema"""
        logger.info("üîß Executando setup inicial...")
        
        # Identificar itens mais populares
        popular_items = await self._get_popular_items()
        
        # Treinar modelos iniciais para top items
        for item in popular_items[:10]:  # Top 10 para in√≠cio
            for model_type in self.config.model_types:
                try:
                    await self._train_single_model(item['item_name'], model_type)
                except Exception as e:
                    logger.warning(f"Falha no treino inicial de {item['item_name']}: {e}")
        
        # Primeira detec√ß√£o de oportunidades
        await self._opportunity_detection_cycle()
        
        logger.info("‚úÖ Setup inicial completado")
    
    async def _daily_model_retraining(self):
        """Retreino di√°rio automatizado de modelos"""
        logger.info("üîÑ Iniciando retreino di√°rio de modelos...")
        
        start_time = datetime.utcnow()
        models_trained = 0
        models_failed = 0
        
        try:
            # Obter itens que precisam de retreino
            items_to_retrain = await self._get_items_for_retraining()
            
            # Retreino paralelo com ThreadPoolExecutor
            with ThreadPoolExecutor(max_workers=4) as executor:
                tasks = []
                
                for item in items_to_retrain:
                    for model_type in self.config.model_types:
                        task = executor.submit(
                            self._retrain_model_sync, 
                            item['item_name'], 
                            model_type
                        )
                        tasks.append((task, item['item_name'], model_type))
                
                # Aguardar conclus√£o
                for task, item_name, model_type in tasks:
                    try:
                        result = task.result(timeout=300)  # 5 min timeout
                        if result['success']:
                            models_trained += 1
                            
                            # Validar performance
                            await self._validate_model_performance(
                                item_name, 
                                model_type, 
                                result
                            )
                        else:
                            models_failed += 1
                            logger.warning(f"Falha no retreino: {item_name} ({model_type})")
                            
                    except Exception as e:
                        models_failed += 1
                        logger.error(f"Erro no retreino {item_name} ({model_type}): {e}")
            
            # Atualizar m√©tricas
            self.system_metrics["models_trained_today"] = models_trained
            
            # Log de resultados
            duration = datetime.utcnow() - start_time
            logger.info(f"‚úÖ Retreino conclu√≠do: {models_trained} sucessos, {models_failed} falhas em {duration}")
            
            # Enviar notifica√ß√£o se muitas falhas
            if models_failed > models_trained * 0.3:  # Mais de 30% de falhas
                async with notification_service as notif:
                    await notif.send_notification({
                        "event_type": "system_alert",
                        "data": {
                            "alert_type": "High Model Training Failure Rate",
                            "message": f"{models_failed} model training failures out of {models_trained + models_failed} attempts",
                            "timestamp": datetime.utcnow().isoformat(),
                            "action_required": "Check system resources and data quality"
                        },
                        "priority": "high"
                    })
        
        except Exception as e:
            logger.error(f"‚ùå Erro cr√≠tico no retreino di√°rio: {e}")
    
    def _retrain_model_sync(self, item_name: str, model_type: str) -> Dict[str, Any]:
        """Wrapper s√≠ncrono para retreino (para usar com ThreadPoolExecutor)"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            async def train_model_async():
                async with prediction_engine as engine:
                    result = await engine.train_model(item_name, model_type, days=90)
                    return result
            
            result = loop.run_until_complete(train_model_async())
            return result
        finally:
            loop.close()
    
    async def _opportunity_detection_cycle(self):
        """Ciclo de detec√ß√£o de oportunidades"""
        logger.info("üîç Executando detec√ß√£o de oportunidades...")
        
        try:
            async with prediction_engine as engine:
                # Detectar oportunidades
                opportunities = await engine.detect_opportunities(min_score=60.0)
                
                self.system_metrics["opportunities_detected_today"] += len(opportunities)
                
                # Processar cada oportunidade
                alerts_sent = 0
                for opportunity in opportunities:
                    try:
                        # Validar oportunidade com m√∫ltiplos modelos
                        validated = await self._validate_opportunity(opportunity)
                        
                        if validated:
                            # Enviar alerta
                            await self._send_opportunity_alert(opportunity)
                            alerts_sent += 1
                            
                    except Exception as e:
                        logger.warning(f"Erro ao processar oportunidade {opportunity.item_name}: {e}")
                
                self.system_metrics["alerts_sent_today"] += alerts_sent
                
                logger.info(f"‚úÖ Detec√ß√£o conclu√≠da: {len(opportunities)} oportunidades, {alerts_sent} alertas enviados")
                
        except Exception as e:
            logger.error(f"‚ùå Erro na detec√ß√£o de oportunidades: {e}")
    
    async def _validate_opportunity(self, opportunity: OpportunityAlert) -> bool:
        """Valida oportunidade usando m√∫ltiplos modelos"""
        try:
            # Obter previs√µes de diferentes modelos
            predictions = []
            
            for model_type in ["xgboost", "prophet"]:
                try:
                    async with prediction_engine as engine:
                        prediction = await engine.predict_price(
                            opportunity.item_name, 
                            horizon="24h", 
                            model_type=model_type
                        )
                        predictions.append(prediction)
                except:
                    continue
            
            if len(predictions) < 2:
                return False
            
            # Consensus entre modelos
            avg_predicted_price = np.mean([p.predicted_price for p in predictions])
            avg_confidence = np.mean([p.confidence for p in predictions])
            
            # Validar se oportunidade √© real
            potential_gain = (avg_predicted_price - opportunity.current_price) / opportunity.current_price
            
            return (
                potential_gain > 0.05 and  # Pelo menos 5% de ganho potencial
                avg_confidence > self.config.confidence_threshold and
                opportunity.confidence > 70.0
            )
            
        except Exception as e:
            logger.warning(f"Erro na valida√ß√£o de oportunidade: {e}")
            return False
    
    async def _send_opportunity_alert(self, opportunity: OpportunityAlert):
        """Envia alerta de oportunidade"""
        try:
            async with notification_service as notif:
                await notif.send_best_deal(
                    item_name=opportunity.item_name,
                    price=opportunity.current_price,
                    market_price=opportunity.fair_value,
                    seller_name="Market Analysis",
                    seller_rating=opportunity.confidence,
                    listing_url=f"https://csfloat.com/search?name={opportunity.item_name}"
                )
                
        except Exception as e:
            logger.error(f"Erro ao enviar alerta: {e}")
    
    async def _performance_monitoring(self):
        """Monitora performance dos modelos"""
        logger.info("üìä Executando monitoramento de performance...")
        
        try:
            # Obter m√©tricas de todos os modelos
            model_metrics = {}
            
            async with prediction_engine as engine:
                all_metrics = engine.get_model_metrics()
                
                for model_key, metric in all_metrics.items():
                    # Calcular accuracy real comparando com pre√ßos atuais
                    actual_accuracy = await self._calculate_real_accuracy(model_key)
                    
                    # Detectar drift
                    drift_score = await self._detect_model_drift(model_key)
                    
                    model_metrics[model_key] = {
                        "accuracy_24h": actual_accuracy,
                        "mae": metric.mae,
                        "r2": metric.r2,
                        "drift_score": drift_score,
                        "last_trained": metric.last_trained,
                        "training_samples": metric.training_samples
                    }
            
            # Identificar modelos que precisam de retreino urgente
            models_needing_retrain = []
            for model_key, metrics in model_metrics.items():
                if (
                    metrics["accuracy_24h"] < self.config.performance_threshold or
                    metrics["drift_score"] > self.config.drift_threshold
                ):
                    models_needing_retrain.append(model_key)
            
            # Retreinar modelos cr√≠ticos imediatamente
            if models_needing_retrain:
                logger.warning(f"‚ö†Ô∏è {len(models_needing_retrain)} modelos precisam de retreino urgente")
                
                for model_key in models_needing_retrain:
                    item_name, model_type = model_key.split("_", 1)
                    try:
                        async with prediction_engine as engine:
                            await engine.train_model(item_name, model_type)
                    except Exception as e:
                        logger.error(f"Erro no retreino urgente de {model_key}: {e}")
            
            # Atualizar m√©tricas do sistema
            if model_metrics:
                self.system_metrics["avg_model_accuracy"] = np.mean([
                    m["accuracy_24h"] for m in model_metrics.values()
                ])
            
            logger.info(f"‚úÖ Monitoramento conclu√≠do: {len(model_metrics)} modelos analisados")
            
        except Exception as e:
            logger.error(f"‚ùå Erro no monitoramento de performance: {e}")
    
    async def _calculate_real_accuracy(self, model_key: str) -> float:
        """Calcula accuracy real comparando previs√µes com pre√ßos atuais"""
        try:
            # Mock implementation - em produ√ß√£o, comparar previs√µes passadas com pre√ßos reais
            # Buscar previs√µes dos √∫ltimos dias e comparar com pre√ßos reais
            return np.random.uniform(0.7, 0.9)  # Mock: 70-90% accuracy
            
        except Exception as e:
            logger.warning(f"Erro ao calcular accuracy real: {e}")
            return 0.5
    
    async def _detect_model_drift(self, model_key: str) -> float:
        """Detecta drift no modelo comparando distribui√ß√µes"""
        try:
            # Mock implementation - em produ√ß√£o, comparar distribui√ß√£o de features
            # entre dados de treino e dados atuais
            return np.random.uniform(0.0, 0.4)  # Mock: 0-40% drift
            
        except Exception as e:
            logger.warning(f"Erro ao detectar drift: {e}")
            return 0.0
    
    async def _generate_daily_report(self):
        """Gera relat√≥rio di√°rio do sistema"""
        logger.info("üìã Gerando relat√≥rio di√°rio...")
        
        try:
            report = {
                "date": datetime.utcnow().date().isoformat(),
                "system_metrics": self.system_metrics.copy(),
                "model_summary": await self._get_model_summary(),
                "opportunities_summary": await self._get_opportunities_summary(),
                "alerts_summary": await self._get_alerts_summary(),
                "performance_issues": await self._get_performance_issues(),
                "recommendations": await self._generate_recommendations()
            }
            
            # Salvar relat√≥rio
            report_path = f"ml_automation/reports/daily_report_{datetime.utcnow().strftime('%Y%m%d')}.json"
            with open(report_path, "w") as f:
                json.dump(report, f, indent=2, default=str)
            
            # Enviar relat√≥rio por email/Telegram se configurado
            await self._send_daily_report(report)
            
            logger.info(f"‚úÖ Relat√≥rio di√°rio salvo: {report_path}")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar relat√≥rio di√°rio: {e}")
    
    async def _send_daily_report(self, report: Dict[str, Any]):
        """Envia relat√≥rio di√°rio via notifica√ß√µes"""
        try:
            summary = f"""
üìä **Relat√≥rio Di√°rio Skinlytics**
üìÖ Data: {report['date']}

ü§ñ **Modelos:**
‚Ä¢ Treinados hoje: {report['system_metrics']['models_trained_today']}
‚Ä¢ Accuracy m√©dia: {report['system_metrics']['avg_model_accuracy']:.1%}

üîç **Oportunidades:**
‚Ä¢ Detectadas: {report['system_metrics']['opportunities_detected_today']}
‚Ä¢ Alertas enviados: {report['system_metrics']['alerts_sent_today']}

üìà **Performance:**
‚Ä¢ Uptime: {(datetime.utcnow() - report['system_metrics']['system_uptime_start']).days} dias
‚Ä¢ Previs√µes total: {report['system_metrics']['total_predictions_made']}
"""
            
            async with notification_service as notif:
                await notif.send_notification({
                    "event_type": "market_trend",
                    "data": {
                        "period": "Daily Report",
                        "summary": summary,
                        "items_count": report['system_metrics']['models_trained_today']
                    },
                    "priority": "normal"
                })
                
        except Exception as e:
            logger.warning(f"Erro ao enviar relat√≥rio: {e}")
    
    async def _system_maintenance(self):
        """Executa manuten√ß√£o do sistema"""
        logger.info("üîß Executando manuten√ß√£o do sistema...")
        
        try:
            # Limpeza de logs antigos
            self._cleanup_old_logs()
            
            # Limpeza de modelos obsoletos
            await self._cleanup_old_models()
            
            # Reset de m√©tricas di√°rias
            self.system_metrics.update({
                "models_trained_today": 0,
                "opportunities_detected_today": 0,
                "alerts_sent_today": 0
            })
            
            # Compacta√ß√£o de dados antigos
            await self._compact_old_data()
            
            logger.info("‚úÖ Manuten√ß√£o conclu√≠da")
            
        except Exception as e:
            logger.error(f"‚ùå Erro na manuten√ß√£o: {e}")
    
    def _cleanup_old_logs(self):
        """Remove logs antigos"""
        try:
            logs_dir = Path("ml_automation/logs")
            cutoff_date = datetime.utcnow() - timedelta(days=30)
            
            for log_file in logs_dir.glob("*.log"):
                if log_file.stat().st_mtime < cutoff_date.timestamp():
                    log_file.unlink()
                    logger.info(f"üóëÔ∏è Log removido: {log_file}")
                    
        except Exception as e:
            logger.warning(f"Erro na limpeza de logs: {e}")
    
    async def _cleanup_old_models(self):
        """Remove modelos obsoletos"""
        try:
            models_dir = Path("ml_automation/models")
            cutoff_date = datetime.utcnow() - timedelta(days=7)
            
            for model_file in models_dir.glob("*.pkl"):
                if model_file.stat().st_mtime < cutoff_date.timestamp():
                    # Verificar se modelo ainda est√° em uso
                    model_key = model_file.stem
                    
                    async with prediction_engine as engine:
                        if model_key not in engine.models:
                            model_file.unlink()
                            logger.info(f"üóëÔ∏è Modelo removido: {model_file}")
                            
        except Exception as e:
            logger.warning(f"Erro na limpeza de modelos: {e}")
    
    async def _compact_old_data(self):
        """Compacta dados antigos no banco"""
        try:
            # Em ClickHouse, otimizar parti√ß√µes antigas
            query = """
            OPTIMIZE TABLE listings_analytics 
            PARTITION tuple(toYYYYMM(created_at_csfloat))
            WHERE toYYYYMM(created_at_csfloat) < toYYYYMM(now() - INTERVAL 3 MONTH)
            """
            
            await self.hybrid_db.query(query, complexity='maintenance')
            logger.info("‚úÖ Dados compactados")
            
        except Exception as e:
            logger.warning(f"Erro na compacta√ß√£o: {e}")
    
    async def _backup_models(self):
        """Backup semanal de modelos"""
        logger.info("üíæ Executando backup de modelos...")
        
        try:
            # Criar backup compactado
            import tarfile
            
            backup_path = f"ml_automation/backups/models_backup_{datetime.utcnow().strftime('%Y%m%d')}.tar.gz"
            Path("ml_automation/backups").mkdir(exist_ok=True)
            
            with tarfile.open(backup_path, "w:gz") as tar:
                tar.add("ml_automation/models", arcname="models")
                tar.add("ml_automation/reports", arcname="reports")
            
            logger.info(f"‚úÖ Backup criado: {backup_path}")
            
        except Exception as e:
            logger.error(f"‚ùå Erro no backup: {e}")
    
    # Helper methods
    async def _get_popular_items(self) -> List[Dict[str, Any]]:
        """Obt√©m itens mais populares para monitoramento"""
        query = """
        SELECT 
            item_name,
            count() as listings_count,
            avg(price_usd) as avg_price,
            stddev(price_usd) as price_volatility
        FROM listings_analytics 
        WHERE created_at_csfloat >= now() - INTERVAL 7 DAY
        GROUP BY item_name
        HAVING listings_count > 50
        ORDER BY listings_count DESC, price_volatility DESC
        LIMIT :limit
        """
        
        return await self.hybrid_db.query(
            query, 
            {"limit": self.config.top_items_to_monitor},
            complexity='analytics'
        )
    
    async def _get_items_for_retraining(self) -> List[Dict[str, Any]]:
        """Identifica itens que precisam de retreino"""
        # Combinar itens populares + itens com modelos desatualizados
        popular_items = await self._get_popular_items()
        
        # Filtrar por idade do √∫ltimo treino
        items_to_retrain = []
        cutoff_time = datetime.utcnow() - timedelta(hours=self.config.retrain_interval_hours)
        
        for item in popular_items:
            # Verificar se modelo existe e est√° desatualizado
            needs_retrain = True
            
            for model_type in self.config.model_types:
                model_key = f"{item['item_name']}_{model_type}"
                
                async with prediction_engine as engine:
                    if model_key in engine.model_metrics:
                        last_trained = engine.model_metrics[model_key].last_trained
                        if last_trained > cutoff_time:
                            needs_retrain = False
                            break
            
            if needs_retrain:
                items_to_retrain.append(item)
        
        return items_to_retrain
    
    async def _get_model_summary(self) -> Dict[str, Any]:
        """Resumo de modelos ativos"""
        async with prediction_engine as engine:
            metrics = engine.get_model_metrics()
            
            return {
                "total_models": len(metrics),
                "avg_accuracy": np.mean([m.accuracy_24h for m in metrics.values()]) if metrics else 0,
                "models_by_type": self._count_models_by_type(metrics),
                "latest_trained": max([m.last_trained for m in metrics.values()]).isoformat() if metrics else None
            }
    
    def _count_models_by_type(self, metrics: Dict) -> Dict[str, int]:
        """Conta modelos por tipo"""
        counts = {}
        for model_key in metrics.keys():
            model_type = model_key.split("_")[-1]
            counts[model_type] = counts.get(model_type, 0) + 1
        return counts
    
    async def _get_opportunities_summary(self) -> Dict[str, Any]:
        """Resumo de oportunidades"""
        return {
            "detected_today": self.system_metrics["opportunities_detected_today"],
            "detection_rate": self.system_metrics["opportunities_detected_today"] / 48,  # Por ciclo de 30min
            "top_categories": ["rifles", "knives", "gloves"]  # Mock
        }
    
    async def _get_alerts_summary(self) -> Dict[str, Any]:
        """Resumo de alertas"""
        return {
            "sent_today": self.system_metrics["alerts_sent_today"],
            "success_rate": 95.0,  # Mock
            "channels_used": ["telegram", "email", "discord"]
        }
    
    async def _get_performance_issues(self) -> List[str]:
        """Lista problemas de performance"""
        issues = []
        
        if self.system_metrics["avg_model_accuracy"] < 0.7:
            issues.append("Accuracy m√©dia dos modelos abaixo de 70%")
        
        if self.system_metrics["models_trained_today"] == 0:
            issues.append("Nenhum modelo treinado hoje")
        
        return issues
    
    async def _generate_recommendations(self) -> List[str]:
        """Gera recomenda√ß√µes baseadas nas m√©tricas"""
        recommendations = []
        
        if self.system_metrics["avg_model_accuracy"] < 0.75:
            recommendations.append("Considerar aumentar dados de treino ou ajustar hiperpar√¢metros")
        
        if self.system_metrics["opportunities_detected_today"] < 10:
            recommendations.append("Verificar thresholds de detec√ß√£o de oportunidades")
        
        recommendations.append("Sistema funcionando dentro dos par√¢metros normais")
        
        return recommendations
    
    def get_system_status(self) -> Dict[str, Any]:
        """Retorna status completo do sistema"""
        return {
            "running": self.running,
            "uptime": datetime.utcnow() - self.system_metrics["system_uptime_start"],
            "metrics": self.system_metrics.copy(),
            "config": asdict(self.config),
            "next_scheduled_tasks": self._get_next_scheduled_tasks()
        }
    
    def _get_next_scheduled_tasks(self) -> List[str]:
        """Retorna pr√≥ximas tarefas agendadas"""
        return [
            f"Daily retrain: {schedule.next_run().strftime('%Y-%m-%d %H:%M')}",
            f"Opportunity detection: Every {self.config.opportunity_check_interval_minutes} minutes",
            f"Performance monitoring: Every 6 hours",
            f"Daily report: Daily at 08:00"
        ]
    
    async def stop_automation(self):
        """Para o sistema de automa√ß√£o"""
        logger.info("üõë Parando automa√ß√£o de ML...")
        
        self.running = False
        
        if self.scheduler_thread and self.scheduler_thread.is_alive():
            self.scheduler_thread.join(timeout=30)
        
        if self.hybrid_db:
            await self.hybrid_db.disconnect()
        
        logger.info("‚úÖ Automa√ß√£o parada")

# Interface CLI
async def main():
    """Interface principal da automa√ß√£o"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Skinlytics ML Automation")
    parser.add_argument("--action", choices=["start", "status", "stop"], default="start")
    parser.add_argument("--config", help="Arquivo de configura√ß√£o")
    
    args = parser.parse_args()
    
    # Carregar config se especificado
    config = AutomationConfig()
    if args.config and Path(args.config).exists():
        with open(args.config) as f:
            config_data = json.load(f)
            config = AutomationConfig(**config_data)
    
    # Inicializar engine
    automation = MLAutomationEngine(config)
    
    if args.action == "start":
        await automation.start_automation()
        
        # Manter rodando
        try:
            while automation.running:
                await asyncio.sleep(60)
        except KeyboardInterrupt:
            logger.info("üõë Interrompido pelo usu√°rio")
            await automation.stop_automation()
    
    elif args.action == "status":
        status = automation.get_system_status()
        print(json.dumps(status, indent=2, default=str))
    
    elif args.action == "stop":
        await automation.stop_automation()

if __name__ == "__main__":
    # Configurar logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s'
    )
    
    asyncio.run(main())